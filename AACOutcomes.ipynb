{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikalajjjj/Data-Mining-Animal_Shelter/blob/main/AACOutcomes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB7pW8uEWsIl"
      },
      "source": [
        "# Classification: Austin Animal Center Outcomes\n",
        "- Intro to Data Mining CS 363D\n",
        "- Project Group 46\n",
        "\n",
        "Can we predict whether an animal in the Austin Animal Center will be adopted, transfered, or euthanized? Here, we perform multi-class classification on an animal's `Outcome Type`, using features from the [Austin Animal Center Intakes dataset](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Intakes/wter-evkm). The class label (`Outcome Type`) is from the [Animal Center Outcomes dataset](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Outcomes/9t4d-g238); these data sets are joined on `Animal ID`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VZeKBaNiVXH",
        "outputId": "055d618b-af77-4c5d-a920-d72962e49658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W_UrIIrvid4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e58f18d-d05f-42ce-daed-c830bf49dd5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 24.7M    0 24.7M    0     0  2172k      0 --:--:--  0:00:11 --:--:-- 1921k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 20.3M    0 20.3M    0     0   884k      0 --:--:--  0:00:23 --:--:-- 1004k\n"
          ]
        }
      ],
      "source": [
        "!curl -o intakes.csv \"https://data.austintexas.gov/api/views/wter-evkm/rows.csv?accessType=DOWNLOAD\"\n",
        "!curl -o outcomes.csv \"https://data.austintexas.gov/api/views/9t4d-g238/rows.csv?accessType=DOWNLOAD\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7ocwS8ZSj4m8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn as sk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9J5v8fSWsIw"
      },
      "source": [
        "## Data Prep\n",
        "\n",
        "- We join the 2 datasets: Intakes and Outcomes on their common column `Animal ID`.\n",
        "- Some Animal IDs have multiple intakes/outcomes.\n",
        "    - Number the duplicates (based on DateTime).\n",
        "    - Pair intakes and outcomes based on Animal ID and Duplicate Number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "EN5vaUM3kAFz",
        "outputId": "5c4aa9b6-7bf4-4672-aec4-ea5f15647d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(173812, 13)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Animal ID    Name            DateTime     MonthYear  \\\n",
              "0   A521520    Nina 2013-10-01 07:51:00  October 2013   \n",
              "1   A664235     NaN 2013-10-01 08:33:00  October 2013   \n",
              "2   A664236     NaN 2013-10-01 08:33:00  October 2013   \n",
              "3   A664237     NaN 2013-10-01 08:33:00  October 2013   \n",
              "4   A664233  Stevie 2013-10-01 08:53:00  October 2013   \n",
              "\n",
              "                   Found Location Intake Type Intake Condition Animal Type  \\\n",
              "0         Norht Ec in Austin (TX)       Stray           Normal         Dog   \n",
              "1             Abia in Austin (TX)       Stray           Normal         Cat   \n",
              "2             Abia in Austin (TX)       Stray           Normal         Cat   \n",
              "3             Abia in Austin (TX)       Stray           Normal         Cat   \n",
              "4  7405 Springtime in Austin (TX)       Stray          Injured         Dog   \n",
              "\n",
              "  Sex upon Intake  Age upon Intake                         Breed  \\\n",
              "0   Spayed Female         7.000000  Border Terrier/Border Collie   \n",
              "1         Unknown         0.019178        Domestic Shorthair Mix   \n",
              "2         Unknown         0.019178        Domestic Shorthair Mix   \n",
              "3         Unknown         0.019178        Domestic Shorthair Mix   \n",
              "4   Intact Female         3.000000                  Pit Bull Mix   \n",
              "\n",
              "          Color  Duplicate Number  \n",
              "0     White/Tan                 0  \n",
              "1  Orange/White                 0  \n",
              "2  Orange/White                 0  \n",
              "3  Orange/White                 0  \n",
              "4    Blue/White                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cf9fed4-f55b-4b64-8fd0-58f294580aa4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Animal ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>MonthYear</th>\n",
              "      <th>Found Location</th>\n",
              "      <th>Intake Type</th>\n",
              "      <th>Intake Condition</th>\n",
              "      <th>Animal Type</th>\n",
              "      <th>Sex upon Intake</th>\n",
              "      <th>Age upon Intake</th>\n",
              "      <th>Breed</th>\n",
              "      <th>Color</th>\n",
              "      <th>Duplicate Number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A521520</td>\n",
              "      <td>Nina</td>\n",
              "      <td>2013-10-01 07:51:00</td>\n",
              "      <td>October 2013</td>\n",
              "      <td>Norht Ec in Austin (TX)</td>\n",
              "      <td>Stray</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Dog</td>\n",
              "      <td>Spayed Female</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>Border Terrier/Border Collie</td>\n",
              "      <td>White/Tan</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A664235</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013-10-01 08:33:00</td>\n",
              "      <td>October 2013</td>\n",
              "      <td>Abia in Austin (TX)</td>\n",
              "      <td>Stray</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Cat</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.019178</td>\n",
              "      <td>Domestic Shorthair Mix</td>\n",
              "      <td>Orange/White</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A664236</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013-10-01 08:33:00</td>\n",
              "      <td>October 2013</td>\n",
              "      <td>Abia in Austin (TX)</td>\n",
              "      <td>Stray</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Cat</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.019178</td>\n",
              "      <td>Domestic Shorthair Mix</td>\n",
              "      <td>Orange/White</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A664237</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013-10-01 08:33:00</td>\n",
              "      <td>October 2013</td>\n",
              "      <td>Abia in Austin (TX)</td>\n",
              "      <td>Stray</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Cat</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0.019178</td>\n",
              "      <td>Domestic Shorthair Mix</td>\n",
              "      <td>Orange/White</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A664233</td>\n",
              "      <td>Stevie</td>\n",
              "      <td>2013-10-01 08:53:00</td>\n",
              "      <td>October 2013</td>\n",
              "      <td>7405 Springtime in Austin (TX)</td>\n",
              "      <td>Stray</td>\n",
              "      <td>Injured</td>\n",
              "      <td>Dog</td>\n",
              "      <td>Intact Female</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>Pit Bull Mix</td>\n",
              "      <td>Blue/White</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cf9fed4-f55b-4b64-8fd0-58f294580aa4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4cf9fed4-f55b-4b64-8fd0-58f294580aa4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4cf9fed4-f55b-4b64-8fd0-58f294580aa4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2242e1e6-80f8-4c43-ad7d-4a9a721dc33a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2242e1e6-80f8-4c43-ad7d-4a9a721dc33a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2242e1e6-80f8-4c43-ad7d-4a9a721dc33a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "intakes"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "intakes = pd.read_csv(\"intakes.csv\")\n",
        "intakes[\"DateTime\"] = pd.to_datetime(intakes[\"DateTime\"])\n",
        "intakes.sort_values(by=\"DateTime\", inplace=True) # sort by date\n",
        "intakes['Duplicate Number'] = intakes.groupby(['Animal ID']).cumcount() # Mark duplicate entries\n",
        "\n",
        "# Age upon Intake: translate into Age upon Intake_NumYearsOld\n",
        "def getNumYearsOld(age_str):\n",
        "    months_in_a_year = 12\n",
        "    weeks_in_a_year = 52.143\n",
        "    days_in_a_year = 365.25\n",
        "    year_idx = age_str.find(\"year\")-1\n",
        "    if(year_idx >= 0):\n",
        "        return float(age_str[:year_idx])\n",
        "    month_idx = age_str.find(\"month\")-1\n",
        "    if(month_idx >= 0):\n",
        "        return float(age_str[:month_idx])/months_in_a_year\n",
        "    weeks_idx = age_str.find(\"week\")-1\n",
        "    if(weeks_idx >= 0):\n",
        "        return float(age_str[:weeks_idx])/weeks_in_a_year\n",
        "    days_idx = age_str.find(\"day\")-1\n",
        "    if(days_idx >= 0):\n",
        "        return float(age_str[:days_idx])/days_in_a_year\n",
        "    return None\n",
        "\n",
        "intakes[\"Age upon Intake\"] = intakes[\"Age upon Intake\"].apply(getNumYearsOld) # make age in terms of yearas\n",
        "\n",
        "print(intakes.shape)\n",
        "intakes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "iIAi8eni5di1",
        "outputId": "b293095e-00be-494f-b21c-582ab06b91b3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "time data \"2013-10-01T09:31:00\" doesn't match format \"%Y-%m-%dT%H:%M:%S%z\", at position 746. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-835830401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutcomes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outcomes.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutcomes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DateTime\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DateTime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DateTime\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Duplicate Number'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Animal ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Mark duplicate entries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0munique_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mcache_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;31m# GH#45319\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;31m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"mixed\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_strptime_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     result, tz_parsed = objects_to_datetime64(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0mCall\u001b[0m \u001b[0marray_strptime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mfallback\u001b[0m \u001b[0mbehavior\u001b[0m \u001b[0mdepending\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m'errors'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtz_out\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0munit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mstrptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mstrptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mstrptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: time data \"2013-10-01T09:31:00\" doesn't match format \"%Y-%m-%dT%H:%M:%S%z\", at position 746. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
          ]
        }
      ],
      "source": [
        "outcomes = pd.read_csv(\"outcomes.csv\")\n",
        "outcomes[\"DateTime\"] = pd.to_datetime(outcomes[\"DateTime\"])\n",
        "outcomes.sort_values(by=\"DateTime\", inplace=True)\n",
        "outcomes['Duplicate Number'] = outcomes.groupby(['Animal ID']).cumcount() # Mark duplicate entries\n",
        "print(outcomes.shape)\n",
        "outcomes.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGDQE9moDqky"
      },
      "outputs": [],
      "source": [
        "outcomes_label = outcomes[[\"Animal ID\", \"Duplicate Number\", \"DateTime\", \"Outcome Type\"]]\n",
        "outcomes_label = outcomes_label.rename(columns={\"DateTime\": \"DateTime_Outcome\"})\n",
        "print(outcomes_label.shape)\n",
        "outcomes_label.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbtSKMppWsI1"
      },
      "outputs": [],
      "source": [
        "raw_df = intakes.merge(outcomes_label, on=[\"Animal ID\", \"Duplicate Number\"], how=\"inner\").set_index(\"Animal ID\")\n",
        "raw_df.sort_values(by=[\"Animal ID\", \"Duplicate Number\"], inplace=True)\n",
        "raw_df.head()\n",
        "\n",
        "# \"Scamp\" has 3 intakes/outcomes (all resulting in \"Return to Owner\"). They are paired together correctly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSDGYBkyWsI2"
      },
      "outputs": [],
      "source": [
        "raw_df.index = raw_df.index.map(str) + \"_\" + raw_df['Duplicate Number'].map(str)\n",
        "raw_df = raw_df.drop(columns=[\"DateTime_Outcome\", \"Duplicate Number\"])\n",
        "raw_df.index.name = 'Animal ID'\n",
        "\n",
        "\n",
        "\n",
        "raw_df.to_csv(\"raw_full_dataset.csv\")\n",
        "print(raw_df.shape)\n",
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4ggjH-0WsI3"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpKnNWrlEBbE"
      },
      "outputs": [],
      "source": [
        "raw_df.describe(include=\"all\", datetime_is_numeric=True)\n",
        "# don't have a name?\n",
        "# datetime as timedelta - visualize datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdSHMj0_7fz6"
      },
      "outputs": [],
      "source": [
        "raw_df[\"Outcome Type\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFW7dcfiWsI6"
      },
      "outputs": [],
      "source": [
        "#plot = raw_df.loc[raw_df['Outcome Type'] == \"Euthanasia\"].plot.pie(y='', figsize=(5, 5))\n",
        "\n",
        "ax = raw_df.plot.box(column=\"Age upon Intake\", by=\"Outcome Type\", figsize=(10, 8))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5VSwhMrWsI7"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def cumulatively_categorize(df, columns, threshold_freq = .9, num_categories = None):\n",
        "    '''\n",
        "    Only keep categories needed sum to threshold_freq, move rest into \"Other\".\n",
        "    Or, keep top threshold_num categories, and move rest into \"Other\".\n",
        "    '''\n",
        "    df = df.copy()\n",
        "    threshold = threshold_freq*len(df)\n",
        "    for column_name in columns:\n",
        "\n",
        "        counts = df[column_name].value_counts()\n",
        "\n",
        "        s = 0\n",
        "        to_keep = []\n",
        "        for value, count in counts.iteritems():\n",
        "            s += count\n",
        "            to_keep.append(value)\n",
        "\n",
        "            if(num_categories is not None):\n",
        "                # based on num of categories\n",
        "                if(len(to_keep) > num_categories):\n",
        "                    break\n",
        "            else:\n",
        "                # based on frequency\n",
        "                if(s > threshold):\n",
        "                    break\n",
        "\n",
        "        print(to_keep)\n",
        "        df[column_name]=df[column_name].apply(lambda x: x if x in to_keep else 'Other')\n",
        "    return df\n",
        "\n",
        "def show_pie_chart(df, categorical_var, label = \"Outcome Type\"):\n",
        "    gb = df.groupby([label])\n",
        "    outcome_groups = [gb.get_group(x) for x in gb.groups]\n",
        "    outcome_labels = [x for x in gb.groups]\n",
        "\n",
        "    pie_chart_df = pd.DataFrame()\n",
        "\n",
        "    for i, outcome_df in enumerate(outcome_groups):\n",
        "        val_counts = outcome_df[categorical_var].value_counts()\n",
        "        print(outcome_labels[i])\n",
        "        print(val_counts)\n",
        "        pie_chart_df[outcome_labels[i]] = val_counts # this logic is wrong: where does \"Bat\" go?\n",
        "        # Idea: insert empty column with every Breed category, then drop it at the end.\n",
        "\n",
        "    pie_chart_df\n",
        "\n",
        "    print(pie_chart_df)\n",
        "\n",
        "    pie_chart_df.plot.pie(subplots=True, layout=(3,3), figsize=(20, 20)) # TODO: fix the size, make pretty\n",
        "\n",
        "df = raw_df.copy()\n",
        "df['Breed'] = df['Breed'].apply(lambda str: str.replace(\" Mix\", \"\")) # remove Mix\n",
        "\n",
        "show_pie_chart(cumulatively_categorize(df, columns=[\"Breed\"], num_categories=10), \"Breed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45AVPR0WWsI9"
      },
      "outputs": [],
      "source": [
        "df = cumulatively_categorize(df, columns=[\"Breed\"], num_categories = 10)\n",
        "show_pie_chart(raw_df, \"Intake Condition\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHiqisMJWsI-"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo5EHYDZWsI-"
      },
      "outputs": [],
      "source": [
        "df = raw_df.copy()\n",
        "\n",
        "def one_hot_encode(df, columns):\n",
        "    '''\n",
        "    Take a categorical variable, one-hot encode, and join back into dataframe.\n",
        "    '''\n",
        "    for column_name in columns:\n",
        "        one_hot_encoded = pd.get_dummies(df[column_name], prefix=column_name)\n",
        "        df = df.drop(column_name, axis='columns')\n",
        "        df = df.join(one_hot_encoded, on=\"Animal ID\")\n",
        "    return df\n",
        "\n",
        "\n",
        "# Breed: bin less common breeds into \"Other\", one-hot encode\n",
        "df['Breed'] = df['Breed'].apply(lambda str: str.replace(\" Mix\", \"\")) # remove Mix\n",
        "df = cumulatively_categorize(df, columns=[\"Breed\"], num_categories = 10)\n",
        "df = one_hot_encode(df, columns=[\"Breed\"])\n",
        "\n",
        "# Outcome Type: collect Adoption, Return to Owner, Rto-Adopt\n",
        "def collectAdoption(outcome):\n",
        "    if(outcome in [\"Adoption\", \"Return to Owner\", \"Rto-Adopt\"]):\n",
        "        return (\"Adoption/RTO\")\n",
        "    else:\n",
        "        return outcome\n",
        "df[\"Outcome Type\"] = df[\"Outcome Type\"].apply(collectAdoption)\n",
        "df = cumulatively_categorize(df, columns=[\"Outcome Type\"],num_categories=4)\n",
        "df = one_hot_encode(df, columns=[\"Outcome Type\"])\n",
        "\n",
        "# To drop\n",
        "to_drop = [\"Name\", \"MonthYear\", \"Color\", \"Found Location\", \"DateTime\"]\n",
        "df = df.drop(columns=to_drop)\n",
        "\n",
        "# To one-hot encode\n",
        "to_one_hot_encode = [\"Intake Type\", \"Intake Condition\", \"Animal Type\", \"Sex upon Intake\"] # experiment\n",
        "df = cumulatively_categorize(df, columns=to_one_hot_encode)\n",
        "df = one_hot_encode(df, columns=to_one_hot_encode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pxStihaWsJA"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_rPggBPWsJA"
      },
      "outputs": [],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg9R7XtuWsJB"
      },
      "outputs": [],
      "source": [
        "# labels_names = ['Outcome Type_Adoption', 'Outcome Type_Died',\n",
        "#        'Outcome Type_Disposal', 'Outcome Type_Euthanasia',\n",
        "#        'Outcome Type_Missing', 'Outcome Type_Relocate',\n",
        "#        'Outcome Type_Return to Owner', 'Outcome Type_Rto-Adopt',\n",
        "#        'Outcome Type_Transfer',]\n",
        "\n",
        "labels_names = ['Outcome Type_Died',\n",
        "       'Outcome Type_Disposal', 'Outcome Type_Euthanasia',\n",
        "       'Outcome Type_Other', 'Outcome Type_Transfer', 'Outcome Type_Adoption/RTO']\n",
        "labels = df[labels_names]\n",
        "features = df.drop(columns=labels_names)\n",
        "print(\"labels:\",labels.shape)\n",
        "print(\"features:\",features.shape)\n",
        "features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWWH9kU1WsJD"
      },
      "source": [
        "## Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpm6CzAHWsJD"
      },
      "source": [
        "### Test/Train Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL0yV3oIWsJE"
      },
      "outputs": [],
      "source": [
        "from sklearn import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_size = int(.8*len(features))\n",
        "test_size = len(features) - train_size\n",
        "X_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, train_size=train_size, shuffle=False)\n",
        "print(\"length of train set: \")\n",
        "print(len(y_train))\n",
        "print(\"length of test set: \")\n",
        "print(len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RL7uhmvWsJF"
      },
      "outputs": [],
      "source": [
        "from sklearn import *\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "clfO = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
        "clfO = clfO.fit(X_train, y_train)\n",
        "y_predict = clfO.predict(x_test)\n",
        "acc = accuracy_score(y_test, y_predict)\n",
        "print(acc) # need to see precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuEkdYoaWsJG"
      },
      "outputs": [],
      "source": [
        "print(tree.export_text(clfO, feature_names=list(features.columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v036o4auWsJH"
      },
      "outputs": [],
      "source": [
        "# Use `sklearn.tree.DecisionTreeClassifier` to fit a decision tree classifier on the training set. Use entropy as the split criterion.\n",
        "from sklearn import *\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
        "param_grid={\n",
        "    \"max_depth\": [5,10],\n",
        "    \"min_samples_leaf\": [5,10],\n",
        "    \"max_features\": [5,10],\n",
        "}\n",
        "clf = model_selection.GridSearchCV(clf,param_grid=param_grid,cv=5,scoring=\"accuracy\")\n",
        "clf.fit(X_train,y_train)\n",
        "print(clf.best_params_)\n",
        "print(clf.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "labels = df.iloc[:,13]\n",
        "clf = GaussianNB()\n",
        "accs=np.mean(model_selection.cross_val_score(clf, X=features, y=labels,cv=10))\n",
        "print(\"Accuracy NB: \")\n",
        "print(accs.mean())\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = cross_val_predict(clf, features, labels, cv=10)\n",
        "conf_mat = confusion_matrix(labels, y_pred)\n",
        "print(\"Confusion Matrix: \")\n",
        "print(conf_mat)\n",
        "print(\"Classification Report: \")\n",
        "print(classification_report(labels, y_pred))\n"
      ],
      "metadata": {
        "id": "MENw9_gvY33X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# knn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA()\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "from sklearn.pipeline import Pipeline\n",
        "pipe = Pipeline([('scaler', scaler), ('pca', pca), ('knn', knn)])\n",
        "res = cross_val_score(pipe, features, labels, cv=5)\n",
        "print(res.mean())"
      ],
      "metadata": {
        "id": "027y__VOfStT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hvVzewgebewq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKeIkfFIWsJI"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ybt9A4ZWsJJ"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "AACOutcomes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-4ggjH-0WsI3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}